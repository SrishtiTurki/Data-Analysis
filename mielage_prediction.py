# -*- coding: utf-8 -*-
"""Mielage Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iNVjoysAhtI3LCg9XScasU53ofzTZkxm

## **Mielage Prediction**

### **Objective**: To predict the mielage of a vehicle using regression analysis

### **Data Source**: https://github.com/YBI-Foundation/Dataset/raw/main/MPG.csv

**Import Library**
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_percentage_error

"""**Import Data**"""

mileage = pd.read_csv('https://github.com/YBI-Foundation/Dataset/raw/main/MPG.csv')

"""**Describe Data**"""

mileage.describe()

mileage.info()

mileage.head()

mileage.columns

"""**Data Visualization**"""

x_scatter = ['cylinders', 'displacement', 'horsepower', 'weight',
       'acceleration', 'model_year']
y_scatter = ['mpg']

sns.pairplot(mpg , x_vars=x_scatter, y_vars=y_scatter)
plt.show()

"""**Data Preprocessing**"""

mpg = mileage.dropna()
mpg

mpg = mpg.drop_duplicates()
mpg

"""**Define Target Variable (y) and Feature Variables (X)**"""

y = mpg['mpg']
x = mpg[['cylinders', 'displacement', 'horsepower', 'weight',
       'acceleration', 'model_year']]

x.shape

y.shape

"""**Train Test Split**"""

x_train, x_test, y_train, y_test = train_test_split(x,y, train_size=0.8, random_state=2529)
x_train

"""**Modeling**"""

model= LinearRegression()

model.fit(x_train, y_train)

"""**Model Evaluation**"""

model.intercept_

model.coef_

"""**Prediction**"""

y_pred = model.predict(x_test)

x_test

mean_absolute_percentage_error(y_test,y_pred)

"""**Explaination**

**1. Information Arrangement and Exploration**
I have begun by stacking my dataset and performing an introductory exploratory information investigation (EDA). Here are the key steps:

**Loading Information:** I imported my dataset utilizing pandas, apparently from a CSV record or another information source.

**Data Cleaning:** The information didn't require much cleaning, so I dealt with lost values or exceptions as fundamental to guarantee the information was usable for modeling.

**Feature Choice:** I utilized the taking after columns for my model:

'mpg': Target variable (miles per gallon)
'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year': Prescient features
'origin', 'name': Not utilized in modeling (conceivably categorical or non-numeric variables)

**2. Information Visualization**
Scatter Plot Lattice: I utilized a diffuse plot lattice (combine plot) from Seaborn (sns.pairplot) to imagine the connections between my prescient highlights ('cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year') and my target variable ('mpg'). This visualization made a difference in me getting potential correlations and designs within the data.

**3. Demonstrate Building and Training**
Train-Test Part: I part my dataset into preparing and testing sets utilizing train_test_split from sklearn. This step guaranteed that I would assess my show on concealed data.

**Linear Relapse Demonstrate:** I chose Direct Relapse (LinearRegression from sklearn) as my prescient demonstration. Direct Relapse fits a direct demonstration of the information by minimizing the remaining whole of squares between the watched and anticipated targets.

**Model Preparing:** I prepared the Straight Relapse show utilizing the prepared information, where the demonstrate learned the relationship between the highlights and the target variable ('mpg').

**4. Show Evaluation**
Error Metric: I assessed my model's performance using Mean Supreme Rate Blunder (MAPE), which could be a common metric for relapse assignments. MAPE measures the normal supreme rate blunder between anticipated and genuine values.

**Error Esteem:** Accomplishing a mistake of roughly 0.13 recommends that my model's forecasts are inside 13% of the real mileage values on average.

**Summary**
In outline, I effectively built and assessed a mileage expectation show utilizing Direct Relapse. My approach included information stacking, negligible cleaning, including choice, visualization utilizing scramble plots, demonstrating preparing with Direct Relapse, and assessment utilizing MAPE. The accomplished mistake of 0.13 demonstrates a sensibly precise expectation execution.
"""